from pyspark.sql.functions import col
from pyspark.sql.types import IntegerType, DoubleType, BooleanType, DateType

configs = {"fs.azure.account.auth.type": "OAuth",
"fs.azure.account.oauth.provider.type": "org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider",
"fs.azure.account.oauth2.client.id": "b943465c-8c9a-483a-9044-32aa6b1b27f5",
"fs.azure.account.oauth2.client.secret": 'uJR8Q~sNCDjo._YwKhM8AoHTRb0HOga7W-U3Haf7',
"fs.azure.account.oauth2.client.endpoint": "https://login.microsoftonline.com/7ea1c678-2856-4a20-857c-a71f891840db/oauth2/token"}

dbutils.fs.mount(
source = "abfss://nba-project@tokyoolympicdata195.dfs.core.windows.net", # contrainer@storageacc
mount_point = "/mnt/nba",
extra_configs = configs)
